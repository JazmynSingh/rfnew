{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#e9eeef; border-right: 10px solid #36b38d ;\" height=300 width=100%>\n",
    "    <font color=#2b3444 size=8 align=left ><strong> Revenue Forecasting</strong></font><br>\n",
    "    <font color=#36b38d size=6 align=left ><strong> Model Training Interface</strong></font>\n",
    "</div>\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from ipywidgets import FileUpload\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import time\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "# import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "# import xgboost as xgb\n",
    "# from math import sqrt\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from scipy.stats import uniform, randint\n",
    "# from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import pydot_ng as pydot\n",
    "# from IPython.display import Image\n",
    "# import math\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from xgboost import XGBRegressor\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "# import sys\n",
    "# import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Model \n",
    "**Predictions can be generated using two models - XGBoost and FBprophet. This dashboard only hosts the XGBoost Model.**\n",
    "\n",
    "**Steps to use the dashboard are listed below**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________________\n",
    "## Steps to Generate Predictions\n",
    "### - Select Pre existing or re-train a new model\n",
    "**You can choose to generate predictions with the existing model. Or you can choose to re-train the model with a new dataset.**\n",
    "\n",
    "**For Existing Model: Each prediction cycle takes a single .csv test file and latest version of PD Sync.The test file MUST contain the month and year columns. If you would like to predict for multiple months, please combine all the months into a single file or predict for one month at a time.**\n",
    "\n",
    "**For example if you would like to generate predictions for 2 months - Nov and Dec. You can either combine the data for both the months in a single file or upload two separate files containing data for Nov and Dec respectively.**\n",
    "\n",
    "**For Re-training: Each prediction cycle takes three files, pd sync, revenue projection and a test file, all three files can be .csv or .xlsx in format. PD Sync and Revenue Projection files are combined to create the training data and the test file is used to generate predictions based on the newly trained model.**\n",
    "\n",
    "\n",
    "### - Select level of training / testing\n",
    "**What are Levels?**\n",
    "\n",
    "**There are 3 levels within which the model can generate predictions. These are - L0, L1 and L2.**\n",
    "\n",
    "**L0 - For predictions at Quantiphi level**\n",
    "\n",
    "**L1 - For predictions at Channel vs. BU level**\n",
    "\n",
    "**L2 - For further predictions within a Channel and BU.** \n",
    "**In channels, only GCP has been considered for predictions due to sufficient data volume. Within GCP predictions can be made for different regions and practices.**\n",
    "\n",
    "**IN BUs, only BFSI has been considered for predictions due to sufficient data volumne. Within BFSI, predictions can be made for deals that are in AWS, GCP or Direct**\n",
    "\n",
    "_______________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Important points before uploading dataset</font>\n",
    "**For pre-existing data, two files are required - latest PD Sync and a test file**\n",
    "* Test file should contain only the following columns with the exact spelling & format - Year , Month ,\tDeal ID\t, Weights , \tStages , Leads UW , Business Unit , Channel\n",
    "* PD Sync file can contain any no. of columns\n",
    "\n",
    "**For re-training data, three files are required - latest PD Sync and a test file**\n",
    "* Test file should contain only the following columns with the exact spelling & format - Year , Month ,\tDeal ID\t, Weights , \tStages , Leads UW , Business Unit , Channel\n",
    "* PD Sync file and Revenue projection file can contain any no. of columns\n",
    "_______________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9b25f7060e49f1b052238b25af0686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<b><font size=4>Select prediction method</b>'), RadioButtons(descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "output_box = widgets.Output()\n",
    "\n",
    "dataset_selector = widgets.RadioButtons(\n",
    "    options=['Predict with existing model', 'Re-train model'],\n",
    "    description='Select: ',\n",
    "    disabled=False\n",
    ")\n",
    "        \n",
    "#######---------------------------------------UPLOADER FUNCTION FOR PRE-EXISTING DATA-----------------------------------########\n",
    "\n",
    "#Uploader function for pd sync test\n",
    "label_pdsync_test=widgets.Label('Please upload PD Sync file in .csv or .xlsx format')\n",
    "uploader_pdsync_test = widgets.FileUpload(multiple=False) \n",
    "\n",
    "\n",
    "get_pdsync_test_button= widgets.Button(description='Next',button_style='info',tooltip='Run')\n",
    "\n",
    "\n",
    "def get_pdsync_test(b):\n",
    "    input_file = list(uploader_pdsync_test.value.values())[0]\n",
    "    content = input_file['content']\n",
    "    #content = io.StringIO(content.decode('utf-8'))\n",
    "    \n",
    "    input_file_Name=input_file['metadata']['name']\n",
    "    File_name_temp1=input_file_Name.split('.')\n",
    "    File_type=File_name_temp1[1]\n",
    "    if File_type=='csv':\n",
    "        df_pdsync_test = pd.read_csv(input_file_Name)\n",
    "    else:\n",
    "        df_pdsync_test = pd.read_excel(content)    \n",
    "\n",
    "#     display(df_pdsync_test)\n",
    "    get_pdsync_test.data = df_pdsync_test\n",
    "    \n",
    "label_test=widgets.Label('Please upload the test file in .xlsx or .csv format')\n",
    "uploader_test = widgets.FileUpload(multiple=False) \n",
    "\n",
    "\n",
    "get_test_button= widgets.Button(description='Next',button_style='info',tooltip='Run')\n",
    "\n",
    "#Uploader function for test data\n",
    "def get_test(b):\n",
    "    input_file = list(uploader_test.value.values())[0]\n",
    "    content = input_file['content']\n",
    "    #content = io.StringIO(content.decode('utf-8'))\n",
    "    \n",
    "    input_file_Name=input_file['metadata']['name']\n",
    "    File_name_temp1=input_file_Name.split('.')\n",
    "    File_type=File_name_temp1[1]\n",
    "    if File_type=='csv':\n",
    "        df_test = pd.read_csv(input_file_Name)\n",
    "    else:\n",
    "        df_test = pd.read_excel(content)    \n",
    "\n",
    "#     display(df_test) \n",
    "    get_test.data = df_test\n",
    "#########--------------------------------------------L1 SELECTOR & FORMATTER FOR EXISTING----------------------------------------------------########    \n",
    "B = widgets.Button(\n",
    "     description='Format Data',\n",
    "     disabled=False,\n",
    "     button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "     tooltip='Click me',\n",
    "     icon='run'\n",
    ")\n",
    "def on_change_l1(change):\n",
    "    with outputlev:\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            if change['new'] == 'GCP':\n",
    "                with outputlev:\n",
    "                    print('GCP Selected')\n",
    "                    display(B)\n",
    "            elif change['new'] == 'BFSI':\n",
    "                with outputlev:\n",
    "                    print('BFSI Selected')\n",
    "                    display(B)\n",
    "            elif change['new'] == 'AWS':\n",
    "                with outputlev:\n",
    "                    print('AWS Selected')  \n",
    "                    display(B)\n",
    "            elif change['new'] == 'TMEG':\n",
    "                with outputlev:\n",
    "                    print('TMEG Selected')\n",
    "                    display(B)\n",
    "            elif change['new'] == 'HCLS':\n",
    "                with outputlev:\n",
    "                    print('HCLS Selected')\n",
    "                    display(B)\n",
    "#########--------------------------------------------L2 SELECTOR & FORMATTER EXISTING----------------------------------------------------########\n",
    "def on_change_l2(change):\n",
    "    with outputlev:\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            if change['new'] == 'GCP-US-East':\n",
    "                with outputlev:\n",
    "                    print('GCP-US-East Region Selected')\n",
    "                    display(B)\n",
    "            elif change['new'] == 'GCP-US-West':\n",
    "                with outputlev:\n",
    "                    print('GCP-US-West Region Selected')\n",
    "                    display(B)\n",
    "            elif change['new'] == 'GCP-US-Central':\n",
    "                with outputlev:\n",
    "                    print('GCP-US-Central Region Selected')\n",
    "                    display(B)        \n",
    "            elif change['new'] == 'BFSI-AWS':\n",
    "                with outputlev:\n",
    "                    print('BFSI-AWS Selected') \n",
    "                    display(B)\n",
    "            elif change['new'] == 'BFSI-Direct':\n",
    "                with outputlev:\n",
    "                    print('BFSI-Direct Selected')\n",
    "                    display(B)\n",
    "            elif change['new'] == 'BFSI-GCP':\n",
    "                with outputlev:\n",
    "                    print('BFSI-GCP Selected')   \n",
    "                    display(B)\n",
    "#########--------------------------------------------LEVEL SELECTOR EXISTING----------------------------------------------------########\n",
    "\n",
    "level_selector = widgets.RadioButtons(\n",
    "                         options=['L0','L1','L2'],\n",
    "                         value=None,\n",
    "                         description='Select Level: ',\n",
    "                         disabled=False,\n",
    "#     layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "level1_selector = widgets.RadioButtons(\n",
    "                         options=['GCP','AWS','BFSI', 'TMEG', 'HCLS'],\n",
    "                         value=None,\n",
    "                         description='Select Level: ',\n",
    "                         disabled=False,\n",
    "#     layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "level2_selector = widgets.RadioButtons(\n",
    "                         options=['BFSI-AWS', 'BFSI-Direct', 'BFSI-GCP', 'GCP-US-Central','GCP-US-East','GCP-US-West'],\n",
    "                         value=None,\n",
    "                         description='Select Level: ',\n",
    "                         disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "lev_button = widgets.Button(\n",
    "description='Format Data',\n",
    "disabled=False,\n",
    "button_style='info', \n",
    "tooltip='Run'\n",
    "    # #     icon='play'\n",
    ")\n",
    "\n",
    "label_level = widgets.Label('Please select level for prediction')\n",
    "\n",
    "def selectlevel(button):\n",
    "    with output_box:\n",
    "        selection = level_selector.get_interact_value()\n",
    "        if (selection == \"L0\"):\n",
    "            with output_box:\n",
    "                display(l0select)\n",
    "                time.sleep(10)\n",
    "                l0_format_test()               \n",
    "        elif (selection ==\"L1\"):\n",
    "            with output_box:\n",
    "                print('L1 Level Selected')\n",
    "                level1_selector.observe(on_change_l1)\n",
    "                display(level1_selector)\n",
    "\n",
    "        elif (selection ==\"L2\"):\n",
    "            with output_box:\n",
    "                print('L2 Level Selected')\n",
    "                level2_selector.observe(on_change_l2)\n",
    "                display(level2_selector)    \n",
    "\n",
    "l0_button = widgets.Button(\n",
    "     description='Format Data',\n",
    "     disabled=False,\n",
    "     button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "     tooltip='Click me',\n",
    "     icon='run'\n",
    ")\n",
    "\n",
    "def lessthanzero(x):\n",
    "    return x <= 0 \n",
    "#########--------------------------------------------L0 FORMATTING TESTING EXISTING----------------------------------------------------########\n",
    "l0_predict_button= widgets.Button(description='Predict',button_style='info',tooltip='Run')\n",
    "text = 'Running Predictions for L0'\n",
    "predictionl0_Widget = widgets.HTML(value = f\"<b><font color='#36b38d' size=5>{text}</b>\")\n",
    "\n",
    "def create_download_link_l0( df, title = \"Download formatted test CSV file\", filename = \"formatted-data.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def create_download_link_l0_final( df, title = \"Download L0 prediction CSV file\", filename = \"prediction-L0.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def l0_format_test():\n",
    "#     df_pdsync_test = df_pdsync_test.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_test = get_test.data\n",
    "    df_pdsync_test = get_pdsync_test.data\n",
    "    df_pdsync_test = df_pdsync_test.drop(columns=['Weights'], axis=1)\n",
    "    df_test = df_test.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_all = df_test.merge(df_pdsync_test.drop_duplicates(), on=['dealid','dealid'], \n",
    "                    how='left', indicator=True)\n",
    "    df_all['Leads UW'] = df_all['Leads UW'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    dropstage = df_all['Stages'].isin(['lost', 'On Hold', 'DA', 'Deleted'])\n",
    "    df_all = df_all[~dropstage]\n",
    "    df_all = df_all[['Year', 'Month', 'dealid', 'Leads UW', 'dealvalue', 'Stages',\n",
    "       'Weights', 'region', 'industry',\n",
    "       'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "    dealvalue_eval = df_all.loc[df_all['dealvalue'].apply(lessthanzero)]\n",
    "    df_all = df_all[~df_all.dealvalue.isin(dealvalue_eval.dealvalue)]\n",
    "    cols2 = ['Stages','region', 'industry',\n",
    "        'billingtype', 'solcategory', 'projectType', 'businessimpact']\n",
    "    df_all[cols2] = df_all[cols2].astype(str)\n",
    "    label_encode_columns = df_all[cols2].apply(LabelEncoder().fit_transform)\n",
    "    cols1 = df_all.select_dtypes([np.number]).columns\n",
    "    numerical = df_all[cols1]\n",
    "    numerical['tmp'] = 1\n",
    "    label_encode_columns['tmp'] = 1\n",
    "    result = pd.concat([numerical, label_encode_columns], axis=1)\n",
    "    result = result.drop(columns=['tmp'])\n",
    "    result['Date'] = pd.to_datetime(result[['Year', 'Month']].assign(DAY=1))\n",
    "    result = result.drop(columns=['Year','Month'])\n",
    "    result = result[['Date',\n",
    "      'dealid',\n",
    "#       'Actuals',\n",
    "      'Weights',\n",
    "      'Leads UW',\n",
    "     'dealvalue',\n",
    "     'Stages',\n",
    "#     #  'PSO/Non-PSO',\n",
    "      'region',\n",
    "#     #  'Practice',\n",
    "#     #  'sourceoflead',\n",
    "       'industry',\n",
    "       'billingtype',\n",
    "       'solcategory',\n",
    "#     #  'Business Category1',\n",
    "       'projectType',\n",
    "#     #  'projectextension',\n",
    "       'businessimpact',\n",
    "    ]]                                \n",
    "                                     \n",
    "    result['Date'] = pd.to_datetime(result['Date'])\n",
    "    result = result.set_index(result['Date'])\n",
    "    result = result.sort_index()\n",
    "    result = result.drop(columns=['Date'])\n",
    "    result = result.rename(columns={\"Stages\": \"Stage\"}) \n",
    "    result = result.rename(columns={\"region\": \"Region\"})\n",
    "    result = result.rename(columns={\"Weights\":\"Weight\"}) \n",
    "    test = result.drop(columns=['dealid'])\n",
    "    test = test[['Weight', 'dealvalue', 'Leads UW', 'Stage', 'Region', 'industry', 'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "#     test = test.apply(pd.to_numeric)\n",
    "    display('Displaying formatted file below: ')\n",
    "    display(test)\n",
    "    display(create_download_link_l0(test))\n",
    "    display(predictionl0_Widget)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    display(\"Predicting.Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    month = df_test['Month'].iloc[1]\n",
    "    year = df_test['Year'].iloc[1]\n",
    "    print(\"Prediction for {}/{} is : \\n\".format(month,year))\n",
    "    display(l0_predict(test))\n",
    "    pred = l0_predict(test)\n",
    "   \n",
    "    df_l0 = pd.DataFrame(data = [[month,year,pred,'nan','nan','nan']], columns=['Month', 'Year', 'Prediction', 'Actuals', 'MAE', 'MAPE'])\n",
    "    display(create_download_link_l0_final(df_l0))\n",
    "    \n",
    "######--------------------------------------------L0 MODEL LOAD TESTING---------------------------------------------------------########    \n",
    "\n",
    "def l0_model():\n",
    "    with open('./xgb_L0.pkl', 'rb') as f:\n",
    "        l0_model = pickle.load(f)\n",
    "    return l0_model\n",
    "\n",
    "def l0_predict(df):\n",
    "         # Feature arragend as per the model\n",
    "    model_l0=l0_model()\n",
    "    predict_l0 = model_l0.predict(df)               # Prediction using the model\n",
    "    prediction = np.sum(predict_l0, dtype=np.int32)      # Predicted result is made into readable format\n",
    "    return prediction\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#######-------------------------------------UPLOADER FUNCTION FOR RE-TRAINING DATA--------------------------------------########\n",
    "\n",
    "#Uploader function for pd sync test\n",
    "label_pdsync_rt=widgets.Label('Please upload PD Sync file in .csv or .xlsx format')\n",
    "uploader_pdsync_rt = widgets.FileUpload(multiple=False) \n",
    "\n",
    "\n",
    "get_pdsync_rt_button= widgets.Button(description='Next',button_style='info',tooltip='Run')\n",
    "\n",
    "\n",
    "def get_pdsync_rt(b):\n",
    "    input_file = list(uploader_pdsync_rt.value.values())[0]\n",
    "    content = input_file['content']\n",
    "    #content = io.StringIO(content.decode('utf-8'))\n",
    "    \n",
    "    input_file_Name=input_file['metadata']['name']\n",
    "    File_name_temp1=input_file_Name.split('.')\n",
    "    File_type=File_name_temp1[1]\n",
    "    if File_type=='csv':\n",
    "        df_pdsync_rt = pd.read_csv(input_file_Name)\n",
    "    else:\n",
    "        df_pdsync_rt = pd.read_excel(content)    \n",
    "\n",
    "#     display(df_pdsync_rt)\n",
    "    get_pdsync_rt.data = df_pdsync_rt\n",
    "    \n",
    "    \n",
    "label_rp=widgets.Label('Please upload the latest rev projections sheet in .xlsx or .csv format')\n",
    "uploader_rp = widgets.FileUpload(multiple=False) \n",
    "\n",
    "\n",
    "get_rp_button= widgets.Button(description='Next',button_style='info',tooltip='Run')\n",
    "\n",
    "#Uploader function for test data\n",
    "def get_rp(b):\n",
    "    input_file = list(uploader_rp.value.values())[0]\n",
    "    content = input_file['content']\n",
    "    #content = io.StringIO(content.decode('utf-8'))\n",
    "    \n",
    "    input_file_Name=input_file['metadata']['name']\n",
    "    File_name_temp1=input_file_Name.split('.')\n",
    "    File_type=File_name_temp1[1]\n",
    "    if File_type=='csv':\n",
    "        df_rp= pd.read_csv(input_file_Name)\n",
    "    else:\n",
    "        df_rp = pd.read_excel(content)    \n",
    "\n",
    "#     display(df_rp) \n",
    "    get_rp.data = df_rp\n",
    "label_test_rt=widgets.Label('Please upload the test sheet for which you want to test the re-trained model in .xlsx or .csv format')\n",
    "uploader_test_rt = widgets.FileUpload(multiple=False) \n",
    "\n",
    "\n",
    "get_rt_button= widgets.Button(description='Next',button_style='info',tooltip='Run')\n",
    "\n",
    "#Uploader function for test data\n",
    "def get_test_rt(b):\n",
    "    input_file = list(uploader_test_rt.value.values())[0]\n",
    "    content = input_file['content']\n",
    "    #content = io.StringIO(content.decode('utf-8'))\n",
    "    \n",
    "    input_file_Name=input_file['metadata']['name']\n",
    "    File_name_temp1=input_file_Name.split('.')\n",
    "    File_type=File_name_temp1[1]\n",
    "    if File_type=='csv':\n",
    "        df_rt= pd.read_csv(input_file_Name)\n",
    "    else:\n",
    "        df_rt = pd.read_excel(content)    \n",
    "#     display(df_rt)\n",
    "    get_test_rt.data = df_rt\n",
    "    \n",
    "#######----------------------------------------LEVEL SELECTOR RE-TRAIN----------------------------------------------############\n",
    "level_selector_rt = widgets.RadioButtons(\n",
    "                         options=['L0','L1','L2'],\n",
    "                         value=None,\n",
    "                         description='Select Level: ',\n",
    "                         disabled=False,\n",
    "#     layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "level1_selector_rt = widgets.RadioButtons(\n",
    "                         options=['GCP','AWS','BFSI', 'TMEG', 'HCLS'],\n",
    "                         value=None,\n",
    "                         description='Select Level: ',\n",
    "                         disabled=False,\n",
    "#     layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "level2_selector_rt = widgets.RadioButtons(\n",
    "                         options=['BFSI-AWS', 'BFSI-Direct', 'BFSI-GCP', 'GCP-US-Central','GCP-US-East','GCP-US-West'],\n",
    "                         value=None,\n",
    "                         description='Select Level: ',\n",
    "                         disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "lev_button_rt = widgets.Button(\n",
    "description='Format Data',\n",
    "disabled=False,\n",
    "button_style='info', \n",
    "tooltip='Run'\n",
    "    # #     icon='play'\n",
    ")\n",
    "\n",
    "label_level_rt = widgets.Label('Please select level for prediction')\n",
    "# l0label = widgets.Label('L0 Level Selected')\n",
    "text1 = 'L0 Level Selected'\n",
    "l0select = widgets.HTML(value = f\"<b><font color='#36b38d' size=3>{text1}</b>\")\n",
    "\n",
    "\n",
    "# l0start = widgets.Button(\n",
    "# description='Next',\n",
    "# disabled=False,\n",
    "# button_style='info', \n",
    "# tooltip='Run'\n",
    "#     # #     icon='play'\n",
    "# )\n",
    "def selectlevel_rt(button):\n",
    "    with output_box:\n",
    "        selection = level_selector_rt.get_interact_value()\n",
    "        if (selection == \"L0\"):\n",
    "            with output_box:\n",
    "                display(l0select)\n",
    "                time.sleep(10)\n",
    "                l0_format_rt()                       \n",
    "        elif (selection ==\"L1\"):\n",
    "            with output_box:\n",
    "                print('L1 Level Selected')\n",
    "#                 level1_selector_rt.observe(on_change_l1_rt)\n",
    "#                 display(level1_selector_rt)\n",
    "\n",
    "        elif (selection ==\"L2\"):\n",
    "            with output_box:\n",
    "                print('L2 Level Selected')\n",
    "#                 level2_selector_rt.observe(on_change_l2_rt)\n",
    "#                 display(level2_selector_rt)    \n",
    "\n",
    "l0_button_rt = widgets.Button(\n",
    "     description='Format Data',\n",
    "     disabled=False,\n",
    "     button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "     tooltip='Click me',\n",
    "     icon='run'\n",
    ")\n",
    "\n",
    "#########-------------------------------------------L0 FORMATTER RE-TRAIN------------------------------------------#############\n",
    "def create_download_link_l0_train( df, title = \"Download formatted training CSV file\", filename = \"formatted-data.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def create_download_link_l0_test( df, title = \"Download formatted test CSV file\", filename = \"formatted-data.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def create_download_link_l0_rt_final( df, title = \"Download L0 prediction CSV file\", filename = \"prediction-L0-RT.csv\"):\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'     \n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "\n",
    "def l0_format_rt():\n",
    "#     df_pdsync_test = df_pdsync_test.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_pdsync_rt = get_pdsync_rt.data\n",
    "    df_pdsync_rt = df_pdsync_rt[['dealid', 'dealvalue','industry', 'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "    df_rp = get_rp.data\n",
    "    df_rp = df_rp[['Year', 'Month', 'Deal ID', 'Stage', 'Weight', 'Actuals', 'Leads UW', 'Region']]\n",
    "#     df_pdsync_test = df_pdsync_test.drop(columns=['Weights'], axis=1)\n",
    "    df_rp = df_rp.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "    df_rp = df_rp.rename(columns={\"Stage\": \"Stages\"})\n",
    "    df_rp = df_rp.rename(columns={\"Weight\": \"Weights\"})\n",
    "    df_rp = df_rp.rename(columns={\"Region\": \"region\"})\n",
    "    df_all = df_rp.merge(df_pdsync_rt.drop_duplicates(), on=['dealid','dealid'], \n",
    "                    how='left', indicator=True)\n",
    "    df_all['Leads UW'] = df_all['Leads UW'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    df_all['Actuals'] = df_all['Actuals'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    dropstage = df_all['Stages'].isin(['lost', 'On Hold', 'DA', 'Deleted'])\n",
    "    df_all = df_all[~dropstage]\n",
    "    df_all = df_all[['Year', 'Month', 'dealid', 'Leads UW', 'Actuals','dealvalue', 'Stages',\n",
    "       'Weights', 'region', 'industry', \n",
    "       'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "    dealvalue_eval = df_all.loc[df_all['dealvalue'].apply(lessthanzero)]\n",
    "    df_all = df_all[~df_all.dealvalue.isin(dealvalue_eval.dealvalue)]\n",
    "    cols2 = ['Stages','region', 'industry',\n",
    "        'billingtype', 'solcategory', 'projectType', 'businessimpact']\n",
    "    df_all[cols2] = df_all[cols2].astype(str)\n",
    "    label_encode_columns = df_all[cols2].apply(LabelEncoder().fit_transform)\n",
    "    cols1 = df_all.select_dtypes([np.number]).columns\n",
    "    numerical = df_all[cols1]\n",
    "    numerical['tmp'] = 1\n",
    "    label_encode_columns['tmp'] = 1\n",
    "    result = pd.concat([numerical, label_encode_columns], axis=1)\n",
    "    result = result.drop(columns=['tmp'])\n",
    "    result['Date'] = pd.to_datetime(result[['Year', 'Month']].assign(DAY=1))\n",
    "    result = result.drop(columns=['Year','Month'])\n",
    "    result = result[['Date',\n",
    "      'dealid',                    \n",
    "      'Actuals',\n",
    "      'Weights',\n",
    "      'Leads UW',\n",
    "     'dealvalue',\n",
    "     'Stages',\n",
    "#     #  'PSO/Non-PSO',\n",
    "      'region',\n",
    "#     #  'Practice',\n",
    "#     #  'sourceoflead',\n",
    "       'industry',\n",
    "       'billingtype',\n",
    "       'solcategory',\n",
    "#     #  'Business Category1',\n",
    "       'projectType',\n",
    "#     #  'projectextension',\n",
    "       'businessimpact',\n",
    "    ]]                                \n",
    "                                     \n",
    "    result['Date'] = pd.to_datetime(result['Date'])\n",
    "    result = result.set_index(result['Date'])\n",
    "    result = result.sort_index()\n",
    "    result = result.drop(columns=['Date'])\n",
    "#     result = result.rename(columns={\"Stages\": \"Stage\"}) \n",
    "#     result = result.rename(columns={\"region\": \"Region\"})\n",
    "#     result = result.rename(columns={\"Weights\":\"Weight\"}) \n",
    "    train = result.drop(columns=['dealid'])\n",
    "    train = train[['Weights', 'dealvalue','Actuals', 'Leads UW', 'Stages', 'region', 'industry', 'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "#     test = test.apply(pd.to_numeric)\n",
    "    \n",
    "    display('Displaying formatted training file below: ')\n",
    "    display(train)\n",
    "    display(create_download_link_l0_train(train))\n",
    "    df_rt = get_test_rt.data\n",
    "    df_rt = df_rt[['Year', 'Month', 'Deal ID', 'Weights', 'Stages', 'Leads UW']]\n",
    "    df_rt = df_rt.rename(columns={\"Deal ID\": \"dealid\"})\n",
    "#     df_rt = df_rt.rename(columns={\"Region\": \"region\"})\n",
    "    df_pdsync_test = get_pdsync_rt.data\n",
    "    df_pdsync_test = df_pdsync_test[['dealid', 'dealvalue','industry', 'billingtype', 'solcategory', 'projectType', 'businessimpact', 'region']]\n",
    "   \n",
    "    df_test = df_rt.merge(df_pdsync_test.drop_duplicates(), on=['dealid','dealid'], \n",
    "                    how='left', indicator=True)\n",
    "    df_test['Leads UW'] = df_test['Leads UW'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "    dropstage = df_test['Stages'].isin(['lost', 'On Hold', 'DA', 'Deleted'])\n",
    "    df_test = df_test[~dropstage]\n",
    "    df_test = df_test[['Year', 'Month', 'dealid', 'Leads UW','dealvalue', 'Stages',\n",
    "       'Weights', 'region', 'industry', \n",
    "       'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "    dealvalue_eval_test = df_test.loc[df_test['dealvalue'].apply(lessthanzero)]\n",
    "    df_test = df_test[~df_test.dealvalue.isin(dealvalue_eval_test.dealvalue)]\n",
    "    cols2_test = ['Stages','region', 'industry',\n",
    "        'billingtype', 'solcategory', 'projectType', 'businessimpact']\n",
    "    df_test[cols2_test] = df_test[cols2_test].astype(str)\n",
    "    label_encode_columns_test = df_test[cols2_test].apply(LabelEncoder().fit_transform)\n",
    "    cols1_test = df_test.select_dtypes([np.number]).columns\n",
    "    numerical_test = df_test[cols1_test]\n",
    "    numerical_test['tmp'] = 1\n",
    "    label_encode_columns_test['tmp'] = 1\n",
    "    result_test = pd.concat([numerical_test, label_encode_columns_test], axis=1)\n",
    "    result_test = result_test.drop(columns=['tmp'])\n",
    "    result_test['Date'] = pd.to_datetime(result_test[['Year', 'Month']].assign(DAY=1))\n",
    "    result_test = result_test.drop(columns=['Year','Month'])\n",
    "    result_test = result_test[['Date',\n",
    "      'dealid',                    \n",
    "#       'Actuals',\n",
    "      'Weights',\n",
    "      'Leads UW',\n",
    "     'dealvalue',\n",
    "     'Stages',\n",
    "#     #  'PSO/Non-PSO',\n",
    "      'region',\n",
    "#     #  'Practice',\n",
    "#     #  'sourceoflead',\n",
    "       'industry',\n",
    "       'billingtype',\n",
    "       'solcategory',\n",
    "#     #  'Business Category1',\n",
    "       'projectType',\n",
    "#     #  'projectextension',\n",
    "       'businessimpact',\n",
    "    ]]                                \n",
    "                                     \n",
    "    result_test['Date'] = pd.to_datetime(result_test['Date'])\n",
    "    result_test = result_test.set_index(result_test['Date'])\n",
    "    result_test = result_test.sort_index()\n",
    "    result_test = result_test.drop(columns=['Date'])\n",
    "\n",
    "    result_test = result_test.drop(columns=['dealid'])\n",
    "    result_test['Actuals'] = np.nan\n",
    "    result_test= result_test[['Weights', 'dealvalue', 'Actuals','Leads UW', 'Stages', 'region', 'industry', 'billingtype', 'solcategory', 'projectType', 'businessimpact']]\n",
    "\n",
    "    display('Displaying formatted testing file below: ')\n",
    "    display(result_test)\n",
    "    display(create_download_link_l0_test(result_test))\n",
    "    x_train = train[[\n",
    "     'Weights',\n",
    "     'dealvalue',\n",
    "     'Leads UW',\n",
    "     'Stages',\n",
    "     'region',\n",
    "     'industry',\n",
    "     'billingtype',\n",
    "     'solcategory',\n",
    "     'projectType',\n",
    "     'businessimpact'\n",
    "    ]]\n",
    "    y_train = train[['Actuals']]\n",
    "    x_test = result_test[[\n",
    "     'Weights',\n",
    "     'dealvalue',\n",
    "     'Leads UW',\n",
    "     'Stages',\n",
    "     'region',\n",
    "     'industry',\n",
    "     'billingtype',\n",
    "     'solcategory',\n",
    "     'projectType',\n",
    "     'businessimpact'\n",
    "    ]]\n",
    "\n",
    "    y_test = result_test[['Actuals']]\n",
    "    \n",
    "    model = XGBRegressor(learning_rate =  0.1, n_estimators=100, colsample_bytree=0.5,max_depth=1)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    pred_sum = y_pred.sum()\n",
    "    text2 = 'Running Predictions for L0'\n",
    "    l0pred = widgets.HTML(value = f\"<b><font color='#36b38d' size=5>{text2}</b>\")\n",
    "    display(l0pred)\n",
    "    month = df_rt['Month'].iloc[1]\n",
    "    year = df_rt['Year'].iloc[1]\n",
    "    print(\"Predicting. Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    print(\"Predicting. Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    print(\"Predicting. Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    print(\"Predicting. Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    print(\"Predicting. Please Wait..\")\n",
    "    time.sleep(10)\n",
    "    print(\"Predicting. Please Wait..\\n\\n\")\n",
    "    time.sleep(5)\n",
    "    print(\"Prediction for {}/{} is : \\n\".format(month,year))\n",
    "    display(pred_sum)\n",
    "    rmse_val = rmse(np.array(y_pred), np.array(y_test))\n",
    "    print(\"\\nTest rmse error is: \" + str(rmse_val))\n",
    "    rmse_val = rmse(np.array(y_pred), np.array(y_train))\n",
    "    print(\"\\nTrain rmse error is: \" + str(rmse_val))\n",
    "    \n",
    "    y_true = y_test.sum()\n",
    "    y_true, pred_sum = np.array(y_true), np.array(pred_sum)\n",
    "    mape =  np.mean(np.abs((y_true - pred_sum) / y_true)) * 100\n",
    "    \n",
    "    mae =  np.mean(np.abs((y_true - pred_sum) / y_true))\n",
    "    print(\"\\nMAPE is: \"+str(mape))\n",
    "    print(\"\\nMAE is: \"+str(mae))\n",
    "    df_l0_rt = pd.DataFrame(data = [[month,year,pred_sum,'nan',mae,mape]], columns=['Month', 'Year', 'Prediction', 'Actuals', 'MAE', 'MAPE'])\n",
    "    display(create_download_link_l0_rt_final(df_l0_rt))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "text3 = 'Select dates for retraining'\n",
    "retrainlabel = widgets.HTML(value = f\"<b><font size=4>{text3}</b>\")\n",
    "\n",
    "start_date = widgets.DatePicker(\n",
    "    description='Start Date'\n",
    ")\n",
    "end_date = widgets.DatePicker(\n",
    "       description='End Date'\n",
    ")\n",
    "text4 = 'Pick start date for training'\n",
    "pickdates = widgets.HTML(value = f\"<b><font size=2>{text4}</b>\")\n",
    "startend= widgets.Label(\"Start and end dates are from 1st to 1st, for example if training set contains data from Aug '2020 to Oct'2021 then start date will be 01-08-2021 and end date will be 01-11-2021 (1st Nov).\")\n",
    "lastdate= widgets.Label(\"The last date of the dataset in this case 31st october will also be included.\")\n",
    "text5 = 'Pick end date for training'\n",
    "testingdate = widgets.HTML(value = f\"<b><font size=2>{text5}</b>\")\n",
    "\n",
    "text6 = 'Select level of training/testing'\n",
    "levlab = widgets.HTML(value = f\"<b><font size=4>{text6}</b>\")\n",
    "\n",
    "text7 = 'Select prediction method'\n",
    "predlab = widgets.HTML(value = f\"<b><font size=4>{text7}</b>\")\n",
    "def evaluate(button):\n",
    "    with output_box:\n",
    "        selection = dataset_selector.get_interact_value()\n",
    "\n",
    "        if (selection == \"Predict with existing model\"):\n",
    "    #         existingdata.observe(on_change)\n",
    "            get_pdsync_test_button.on_click(get_pdsync_test)\n",
    "            get_test_button.on_click(get_test)\n",
    "            lev_button.on_click(selectlevel)\n",
    "            left_box_lev = widgets.VBox([level_selector, lev_button])\n",
    "            left_box1=widgets.HBox([uploader_pdsync_test,get_pdsync_test_button])\n",
    "            left_box2=widgets.HBox([uploader_test,get_test_button])\n",
    "            left_box_test=widgets.VBox([label_pdsync_test,left_box1, label_test, left_box2,  levlab, left_box_lev])\n",
    "            with output_box:\n",
    "                    display(left_box_test) \n",
    "                               \n",
    "        elif (selection == \"Re-train model\"):\n",
    "            get_pdsync_rt_button.on_click(get_pdsync_rt)\n",
    "            get_rp_button.on_click(get_rp)\n",
    "            get_rt_button.on_click(get_test_rt)\n",
    "            lev_button_rt.on_click(selectlevel_rt)\n",
    "#             date_button.on_click(date_formatter)\n",
    "            left_box_date_l0_start = widgets.VBox([start_date])\n",
    "            left_box_date_l0_end = widgets.VBox([end_date])\n",
    "            left_box3=widgets.HBox([uploader_pdsync_rt,get_pdsync_rt_button])\n",
    "            left_box4=widgets.HBox([uploader_rp,get_rp_button])\n",
    "            left_box5=widgets.HBox([uploader_test_rt,get_rt_button])\n",
    "            left_box_lev_rt = widgets.VBox([level_selector_rt, lev_button_rt])\n",
    "#             left_box_date = widgets.VBox([date_button])\n",
    "            left_box_retrain=widgets.VBox([label_pdsync_rt,left_box3, label_rp,left_box4,label_test_rt, left_box5,retrainlabel, startend, lastdate, pickdates, start_date, testingdate, end_date,levlab, left_box_lev_rt])\n",
    "            with output_box:\n",
    "                    display(left_box_retrain)\n",
    "#                     display(date_formatter())\n",
    "                    \n",
    "\n",
    "\n",
    "my_button = widgets.Button(\n",
    "     description='Next',\n",
    "     disabled=False,\n",
    "     button_style='info', \n",
    "     tooltip='Run'\n",
    "# #     icon='play'\n",
    ")\n",
    "# output_box = widgets.Output()\n",
    "# # display(my_button, output_box)\n",
    "my_button.on_click(evaluate)\n",
    "left_box = widgets.VBox([predlab, dataset_selector, my_button,output_box])\n",
    "widgets.HBox([left_box])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
